{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for CD GANs on this site: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import imageio\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator and Discriminator Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):   # All images are 28x28 (784=28^2)\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 4 x 4\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 7 x 7\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 14 x 14\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 28 x 28\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):  # if the dimensions of the image change, we'll need to change the layout\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 28 x 28\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 14 x 14\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 7 x 7\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining networks and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 1\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 28\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 28\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following may be used for reference later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ngpu = 1\\n\\n# Create the generator\\nnetG = Generator().to(device)\\n\\n# Handle multi-gpu if desired\\nif (device.type == 'cuda') and (ngpu > 1):\\n    netG = nn.DataParallel(netG, list(range(ngpu)))\\n\\n# Apply the weights_init function to randomly initialize all weights\\n#  to mean=0, stdev=0.2.\\nnetG.apply(weights_init)\\n\\n# Print the model\\nprint(netG)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ngpu = 1\n",
    "\n",
    "# Create the generator\n",
    "netG = Generator().to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create the Discriminator\\nnetD = Discriminator(ngpu).to(device)\\n\\n# Handle multi-gpu if desired\\nif (device.type == 'cuda') and (ngpu > 1):\\n    netD = nn.DataParallel(netD, list(range(ngpu)))\\n\\n# Apply the weights_init function to randomly initialize all weights\\n#  to mean=0, stdev=0.2.\\nnetD.apply(weights_init)\\n\\n# Print the model\\nprint(netD)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([       # Make sure to change the parameters accordingly\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,),(0.5,))\n",
    "                ])\n",
    "to_image = transforms.ToPILImage()\n",
    "trainset = MNIST(root='./data/', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=workers)  # This draws the data from MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    n = real_data.size(0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction_real = discriminator(real_data)\n",
    "    error_real = criterion(prediction_real, make_ones(n))\n",
    "    error_real.backward()\n",
    "\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    error_fake = criterion(prediction_fake, make_zeros(n))\n",
    "    \n",
    "    error_fake.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return error_real + error_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_generator(optimizer, fake_data):\n",
    "    n = fake_data.size(0)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction = discriminator(fake_data)\n",
    "    error = criterion(prediction, make_ones(n))\n",
    "    \n",
    "    error.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "g_optim = optim.Adam(generator.parameters(), lr=2e-4)\n",
    "d_optim = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
    "\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "images = []\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def noise(n, n_features=128):\n",
    "    return Variable(torch.randn(n, n_features)).to(device)\n",
    "\n",
    "def make_ones(size):\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data.to(device)\n",
    "\n",
    "def make_zeros(size):\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/100][0/3000]\tLoss_D: 1.6384\tLoss_G: 0.6737\tD(x): 0.4176\tD(G(z)): 0.5137 / 0.5137\n",
      "[0/100][50/3000]\tLoss_D: 1.5663\tLoss_G: 0.6828\tD(x): 0.4393\tD(G(z)): 0.5090 / 0.5090\n",
      "[0/100][100/3000]\tLoss_D: 1.5925\tLoss_G: 0.6823\tD(x): 0.4348\tD(G(z)): 0.5123 / 0.5123\n",
      "[0/100][150/3000]\tLoss_D: 1.6352\tLoss_G: 0.6515\tD(x): 0.4207\tD(G(z)): 0.5241 / 0.5241\n",
      "[0/100][200/3000]\tLoss_D: 1.6409\tLoss_G: 0.7189\tD(x): 0.3991\tD(G(z)): 0.4925 / 0.4925\n",
      "[0/100][250/3000]\tLoss_D: 1.6469\tLoss_G: 0.6847\tD(x): 0.4059\tD(G(z)): 0.5092 / 0.5092\n",
      "[0/100][300/3000]\tLoss_D: 1.6566\tLoss_G: 0.6341\tD(x): 0.4278\tD(G(z)): 0.5365 / 0.5365\n",
      "[0/100][350/3000]\tLoss_D: 1.7087\tLoss_G: 0.6984\tD(x): 0.3720\tD(G(z)): 0.5014 / 0.5014\n",
      "[0/100][400/3000]\tLoss_D: 1.4965\tLoss_G: 0.7176\tD(x): 0.4479\tD(G(z)): 0.4915 / 0.4915\n",
      "[0/100][450/3000]\tLoss_D: 1.6874\tLoss_G: 0.6637\tD(x): 0.4048\tD(G(z)): 0.5227 / 0.5227\n",
      "[0/100][500/3000]\tLoss_D: 1.5658\tLoss_G: 0.7270\tD(x): 0.4207\tD(G(z)): 0.4916 / 0.4916\n",
      "[0/100][550/3000]\tLoss_D: 1.6205\tLoss_G: 0.6429\tD(x): 0.4438\tD(G(z)): 0.5349 / 0.5349\n",
      "[0/100][600/3000]\tLoss_D: 1.5557\tLoss_G: 0.7465\tD(x): 0.4175\tD(G(z)): 0.4786 / 0.4786\n",
      "[0/100][650/3000]\tLoss_D: 1.5677\tLoss_G: 0.7331\tD(x): 0.4260\tD(G(z)): 0.4896 / 0.4896\n",
      "[0/100][700/3000]\tLoss_D: 1.5776\tLoss_G: 0.7419\tD(x): 0.4105\tD(G(z)): 0.4808 / 0.4808\n",
      "[0/100][750/3000]\tLoss_D: 1.5634\tLoss_G: 0.7670\tD(x): 0.4160\tD(G(z)): 0.4722 / 0.4722\n",
      "[0/100][800/3000]\tLoss_D: 1.5482\tLoss_G: 0.7124\tD(x): 0.4448\tD(G(z)): 0.4989 / 0.4989\n",
      "[0/100][850/3000]\tLoss_D: 1.7285\tLoss_G: 0.6579\tD(x): 0.3847\tD(G(z)): 0.5222 / 0.5222\n",
      "[0/100][900/3000]\tLoss_D: 1.5697\tLoss_G: 0.6546\tD(x): 0.4462\tD(G(z)): 0.5233 / 0.5233\n",
      "[0/100][950/3000]\tLoss_D: 1.5694\tLoss_G: 0.6987\tD(x): 0.4311\tD(G(z)): 0.5038 / 0.5038\n",
      "[0/100][1000/3000]\tLoss_D: 1.5897\tLoss_G: 0.7235\tD(x): 0.4167\tD(G(z)): 0.4916 / 0.4916\n",
      "[0/100][1050/3000]\tLoss_D: 1.6120\tLoss_G: 0.6952\tD(x): 0.4202\tD(G(z)): 0.5076 / 0.5076\n",
      "[0/100][1100/3000]\tLoss_D: 1.6135\tLoss_G: 0.7597\tD(x): 0.3943\tD(G(z)): 0.4756 / 0.4756\n",
      "[0/100][1150/3000]\tLoss_D: 1.6578\tLoss_G: 0.6878\tD(x): 0.4042\tD(G(z)): 0.5078 / 0.5078\n",
      "[0/100][1200/3000]\tLoss_D: 1.5954\tLoss_G: 0.7390\tD(x): 0.4032\tD(G(z)): 0.4835 / 0.4835\n",
      "[0/100][1250/3000]\tLoss_D: 1.6336\tLoss_G: 0.7236\tD(x): 0.4005\tD(G(z)): 0.4940 / 0.4940\n",
      "[0/100][1300/3000]\tLoss_D: 1.6365\tLoss_G: 0.7005\tD(x): 0.4179\tD(G(z)): 0.5084 / 0.5084\n",
      "[0/100][1350/3000]\tLoss_D: 1.6353\tLoss_G: 0.7083\tD(x): 0.4061\tD(G(z)): 0.5012 / 0.5012\n",
      "[0/100][1400/3000]\tLoss_D: 1.6957\tLoss_G: 0.6333\tD(x): 0.4124\tD(G(z)): 0.5351 / 0.5351\n",
      "[0/100][1450/3000]\tLoss_D: 1.5980\tLoss_G: 0.6827\tD(x): 0.4339\tD(G(z)): 0.5114 / 0.5114\n",
      "[0/100][1500/3000]\tLoss_D: 1.5622\tLoss_G: 0.6722\tD(x): 0.4460\tD(G(z)): 0.5143 / 0.5143\n",
      "[0/100][1550/3000]\tLoss_D: 1.6434\tLoss_G: 0.6753\tD(x): 0.4198\tD(G(z)): 0.5153 / 0.5153\n",
      "[0/100][1600/3000]\tLoss_D: 1.6149\tLoss_G: 0.6966\tD(x): 0.4215\tD(G(z)): 0.5058 / 0.5058\n",
      "[0/100][1650/3000]\tLoss_D: 1.5990\tLoss_G: 0.7114\tD(x): 0.4191\tD(G(z)): 0.4966 / 0.4966\n",
      "[0/100][1700/3000]\tLoss_D: 1.5710\tLoss_G: 0.6758\tD(x): 0.4379\tD(G(z)): 0.5136 / 0.5136\n",
      "[0/100][1750/3000]\tLoss_D: 1.6743\tLoss_G: 0.6675\tD(x): 0.4048\tD(G(z)): 0.5226 / 0.5226\n",
      "[0/100][1800/3000]\tLoss_D: 1.6665\tLoss_G: 0.6713\tD(x): 0.4050\tD(G(z)): 0.5170 / 0.5170\n",
      "[0/100][1850/3000]\tLoss_D: 1.6325\tLoss_G: 0.6655\tD(x): 0.4172\tD(G(z)): 0.5192 / 0.5192\n",
      "[0/100][1900/3000]\tLoss_D: 1.7025\tLoss_G: 0.6857\tD(x): 0.3895\tD(G(z)): 0.5128 / 0.5128\n",
      "[0/100][1950/3000]\tLoss_D: 1.6178\tLoss_G: 0.7595\tD(x): 0.3979\tD(G(z)): 0.4787 / 0.4787\n",
      "[0/100][2000/3000]\tLoss_D: 1.5334\tLoss_G: 0.7689\tD(x): 0.4156\tD(G(z)): 0.4700 / 0.4700\n",
      "[0/100][2050/3000]\tLoss_D: 1.5412\tLoss_G: 0.7345\tD(x): 0.4234\tD(G(z)): 0.4815 / 0.4815\n",
      "[0/100][2100/3000]\tLoss_D: 1.5430\tLoss_G: 0.7138\tD(x): 0.4382\tD(G(z)): 0.4961 / 0.4961\n",
      "[0/100][2150/3000]\tLoss_D: 1.6772\tLoss_G: 0.6361\tD(x): 0.4148\tD(G(z)): 0.5341 / 0.5341\n",
      "[0/100][2200/3000]\tLoss_D: 1.6364\tLoss_G: 0.6886\tD(x): 0.4147\tD(G(z)): 0.5109 / 0.5109\n",
      "[0/100][2250/3000]\tLoss_D: 1.5759\tLoss_G: 0.7104\tD(x): 0.4289\tD(G(z)): 0.4980 / 0.4980\n",
      "[0/100][2300/3000]\tLoss_D: 1.6121\tLoss_G: 0.7235\tD(x): 0.4027\tD(G(z)): 0.4908 / 0.4908\n",
      "[0/100][2350/3000]\tLoss_D: 1.6308\tLoss_G: 0.6803\tD(x): 0.4150\tD(G(z)): 0.5091 / 0.5091\n",
      "[0/100][2400/3000]\tLoss_D: 1.5798\tLoss_G: 0.6624\tD(x): 0.4398\tD(G(z)): 0.5185 / 0.5185\n",
      "[0/100][2450/3000]\tLoss_D: 1.5855\tLoss_G: 0.7246\tD(x): 0.4175\tD(G(z)): 0.4933 / 0.4933\n",
      "[0/100][2500/3000]\tLoss_D: 1.6878\tLoss_G: 0.6889\tD(x): 0.3983\tD(G(z)): 0.5132 / 0.5132\n",
      "[0/100][2550/3000]\tLoss_D: 1.5949\tLoss_G: 0.7155\tD(x): 0.4199\tD(G(z)): 0.4963 / 0.4963\n",
      "[0/100][2600/3000]\tLoss_D: 1.5728\tLoss_G: 0.6922\tD(x): 0.4310\tD(G(z)): 0.5059 / 0.5059\n",
      "[0/100][2650/3000]\tLoss_D: 1.6820\tLoss_G: 0.7037\tD(x): 0.3920\tD(G(z)): 0.5015 / 0.5015\n",
      "[0/100][2700/3000]\tLoss_D: 1.5960\tLoss_G: 0.7061\tD(x): 0.4223\tD(G(z)): 0.5020 / 0.5020\n",
      "[0/100][2750/3000]\tLoss_D: 1.6367\tLoss_G: 0.6852\tD(x): 0.4061\tD(G(z)): 0.5068 / 0.5068\n",
      "[0/100][2800/3000]\tLoss_D: 1.6400\tLoss_G: 0.6700\tD(x): 0.4073\tD(G(z)): 0.5145 / 0.5145\n",
      "[0/100][2850/3000]\tLoss_D: 1.6245\tLoss_G: 0.7101\tD(x): 0.4070\tD(G(z)): 0.4959 / 0.4959\n",
      "[0/100][2900/3000]\tLoss_D: 1.7012\tLoss_G: 0.6964\tD(x): 0.3920\tD(G(z)): 0.5064 / 0.5064\n",
      "[0/100][2950/3000]\tLoss_D: 1.6564\tLoss_G: 0.6695\tD(x): 0.4103\tD(G(z)): 0.5169 / 0.5169\n",
      "[1/100][0/3000]\tLoss_D: 1.6533\tLoss_G: 0.7377\tD(x): 0.3962\tD(G(z)): 0.4912 / 0.4912\n",
      "[1/100][50/3000]\tLoss_D: 1.6189\tLoss_G: 0.7189\tD(x): 0.4120\tD(G(z)): 0.4958 / 0.4958\n",
      "[1/100][100/3000]\tLoss_D: 1.6530\tLoss_G: 0.6751\tD(x): 0.4082\tD(G(z)): 0.5149 / 0.5149\n",
      "[1/100][150/3000]\tLoss_D: 1.8143\tLoss_G: 0.6026\tD(x): 0.3782\tD(G(z)): 0.5523 / 0.5523\n",
      "[1/100][200/3000]\tLoss_D: 1.5764\tLoss_G: 0.7087\tD(x): 0.4286\tD(G(z)): 0.4987 / 0.4987\n",
      "[1/100][250/3000]\tLoss_D: 1.7084\tLoss_G: 0.6585\tD(x): 0.3913\tD(G(z)): 0.5234 / 0.5234\n",
      "[1/100][300/3000]\tLoss_D: 1.4979\tLoss_G: 0.7493\tD(x): 0.4418\tD(G(z)): 0.4791 / 0.4791\n",
      "[1/100][350/3000]\tLoss_D: 1.7064\tLoss_G: 0.6500\tD(x): 0.4058\tD(G(z)): 0.5298 / 0.5298\n",
      "[1/100][400/3000]\tLoss_D: 1.5979\tLoss_G: 0.7470\tD(x): 0.3992\tD(G(z)): 0.4802 / 0.4802\n",
      "[1/100][450/3000]\tLoss_D: 1.6852\tLoss_G: 0.6929\tD(x): 0.3879\tD(G(z)): 0.5064 / 0.5064\n",
      "[1/100][500/3000]\tLoss_D: 1.6114\tLoss_G: 0.6943\tD(x): 0.4150\tD(G(z)): 0.5039 / 0.5039\n",
      "[1/100][550/3000]\tLoss_D: 1.5895\tLoss_G: 0.6974\tD(x): 0.4277\tD(G(z)): 0.5023 / 0.5023\n",
      "[1/100][600/3000]\tLoss_D: 1.6354\tLoss_G: 0.6789\tD(x): 0.4110\tD(G(z)): 0.5098 / 0.5098\n",
      "[1/100][650/3000]\tLoss_D: 1.6764\tLoss_G: 0.6584\tD(x): 0.4073\tD(G(z)): 0.5244 / 0.5244\n",
      "[1/100][700/3000]\tLoss_D: 1.5204\tLoss_G: 0.7633\tD(x): 0.4322\tD(G(z)): 0.4726 / 0.4726\n",
      "[1/100][750/3000]\tLoss_D: 1.5564\tLoss_G: 0.7449\tD(x): 0.4209\tD(G(z)): 0.4817 / 0.4817\n",
      "[1/100][800/3000]\tLoss_D: 1.6308\tLoss_G: 0.6895\tD(x): 0.4100\tD(G(z)): 0.5087 / 0.5087\n",
      "[1/100][850/3000]\tLoss_D: 1.6179\tLoss_G: 0.6725\tD(x): 0.4330\tD(G(z)): 0.5212 / 0.5212\n",
      "[1/100][900/3000]\tLoss_D: 1.7760\tLoss_G: 0.6540\tD(x): 0.3671\tD(G(z)): 0.5241 / 0.5241\n",
      "[1/100][950/3000]\tLoss_D: 1.6216\tLoss_G: 0.6970\tD(x): 0.4179\tD(G(z)): 0.5039 / 0.5039\n",
      "[1/100][1000/3000]\tLoss_D: 1.5211\tLoss_G: 0.7411\tD(x): 0.4347\tD(G(z)): 0.4803 / 0.4803\n",
      "[1/100][1050/3000]\tLoss_D: 1.7159\tLoss_G: 0.6461\tD(x): 0.3939\tD(G(z)): 0.5303 / 0.5303\n",
      "[1/100][1100/3000]\tLoss_D: 1.5877\tLoss_G: 0.6874\tD(x): 0.4329\tD(G(z)): 0.5090 / 0.5090\n",
      "[1/100][1150/3000]\tLoss_D: 1.6550\tLoss_G: 0.6175\tD(x): 0.4373\tD(G(z)): 0.5449 / 0.5449\n",
      "[1/100][1200/3000]\tLoss_D: 1.5763\tLoss_G: 0.6887\tD(x): 0.4309\tD(G(z)): 0.5072 / 0.5072\n",
      "[1/100][1250/3000]\tLoss_D: 1.5875\tLoss_G: 0.7578\tD(x): 0.4058\tD(G(z)): 0.4770 / 0.4770\n",
      "[1/100][1300/3000]\tLoss_D: 1.5273\tLoss_G: 0.7156\tD(x): 0.4411\tD(G(z)): 0.4946 / 0.4946\n",
      "[1/100][1350/3000]\tLoss_D: 1.4951\tLoss_G: 0.7504\tD(x): 0.4345\tD(G(z)): 0.4739 / 0.4739\n",
      "[1/100][1400/3000]\tLoss_D: 1.5618\tLoss_G: 0.6863\tD(x): 0.4452\tD(G(z)): 0.5109 / 0.5109\n",
      "[1/100][1450/3000]\tLoss_D: 1.5870\tLoss_G: 0.7230\tD(x): 0.4122\tD(G(z)): 0.4888 / 0.4888\n",
      "[1/100][1500/3000]\tLoss_D: 1.6481\tLoss_G: 0.6691\tD(x): 0.4111\tD(G(z)): 0.5169 / 0.5169\n",
      "[1/100][1550/3000]\tLoss_D: 1.6579\tLoss_G: 0.6185\tD(x): 0.4375\tD(G(z)): 0.5428 / 0.5428\n",
      "[1/100][1600/3000]\tLoss_D: 1.6789\tLoss_G: 0.6573\tD(x): 0.4122\tD(G(z)): 0.5275 / 0.5275\n",
      "[1/100][1650/3000]\tLoss_D: 1.6612\tLoss_G: 0.6818\tD(x): 0.3990\tD(G(z)): 0.5103 / 0.5103\n",
      "[1/100][1700/3000]\tLoss_D: 1.5510\tLoss_G: 0.7492\tD(x): 0.4191\tD(G(z)): 0.4785 / 0.4785\n",
      "[1/100][1750/3000]\tLoss_D: 1.7028\tLoss_G: 0.6830\tD(x): 0.3944\tD(G(z)): 0.5153 / 0.5153\n",
      "[1/100][1800/3000]\tLoss_D: 1.5258\tLoss_G: 0.7150\tD(x): 0.4407\tD(G(z)): 0.4919 / 0.4919\n",
      "[1/100][1850/3000]\tLoss_D: 1.5908\tLoss_G: 0.6788\tD(x): 0.4308\tD(G(z)): 0.5137 / 0.5137\n",
      "[1/100][1900/3000]\tLoss_D: 1.5883\tLoss_G: 0.6684\tD(x): 0.4377\tD(G(z)): 0.5202 / 0.5202\n",
      "[1/100][1950/3000]\tLoss_D: 1.5928\tLoss_G: 0.6662\tD(x): 0.4361\tD(G(z)): 0.5195 / 0.5195\n",
      "[1/100][2000/3000]\tLoss_D: 1.6795\tLoss_G: 0.7046\tD(x): 0.3788\tD(G(z)): 0.4969 / 0.4969\n",
      "[1/100][2050/3000]\tLoss_D: 1.5352\tLoss_G: 0.7642\tD(x): 0.4234\tD(G(z)): 0.4755 / 0.4755\n",
      "[1/100][2100/3000]\tLoss_D: 1.6686\tLoss_G: 0.7018\tD(x): 0.3929\tD(G(z)): 0.5020 / 0.5020\n",
      "[1/100][2150/3000]\tLoss_D: 1.6840\tLoss_G: 0.6541\tD(x): 0.4085\tD(G(z)): 0.5293 / 0.5293\n",
      "[1/100][2200/3000]\tLoss_D: 1.6776\tLoss_G: 0.7076\tD(x): 0.3886\tD(G(z)): 0.4986 / 0.4986\n",
      "[1/100][2250/3000]\tLoss_D: 1.6302\tLoss_G: 0.6503\tD(x): 0.4330\tD(G(z)): 0.5270 / 0.5270\n",
      "[1/100][2300/3000]\tLoss_D: 1.6989\tLoss_G: 0.6861\tD(x): 0.3873\tD(G(z)): 0.5108 / 0.5108\n",
      "[1/100][2350/3000]\tLoss_D: 1.5722\tLoss_G: 0.7464\tD(x): 0.4163\tD(G(z)): 0.4835 / 0.4835\n"
     ]
    }
   ],
   "source": [
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "num_epochs = 1\n",
    "netD = Discriminator()\n",
    "netG = Generator()\n",
    "\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Add the gradients from the all-real and all-fake batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "imgs = [np.array(to_image(i)) for i in images]\n",
    "imageio.mimsave('progress.gif', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def plot_result(generator, noise, num_epoch, save=False, save_dir='MNIST_GAN_results/', show=False, fig_size=(5, 5)):\n",
    "    generator.eval()\n",
    "\n",
    "    noise = Variable(noise.cpu())\n",
    "    gen_image = generator(noise)\n",
    "    gen_image = denorm(gen_image)\n",
    "\n",
    "    generator.train()\n",
    "\n",
    "    n_rows = np.sqrt(noise.size()[0]).astype(np.int32)\n",
    "    n_cols = np.sqrt(noise.size()[0]).astype(np.int32)\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=fig_size)\n",
    "    for ax, img in zip(axes.flatten(), gen_image):\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "        ax.imshow(img.cpu().data.view(image_size, image_size).numpy(), cmap='gray', aspect='equal')\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    title = 'Epoch {0}'.format(num_epoch+1)\n",
    "    fig.text(0.5, 0.04, title, ha='center')\n",
    "\n",
    "    # save figure\n",
    "    if save:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.mkdir(save_dir)\n",
    "        save_fn = save_dir + 'MNIST_GAN_epoch_{:d}'.format(num_epoch+1) + '.png'\n",
    "        plt.savefig(save_fn)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_losses, label='Generator_Losses')\n",
    "plt.plot(d_losses, label='Discriminator Losses')\n",
    "plt.legend()\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fixed_noise = torch.randn(n, 128)\n",
    "plot_result(generator, fixed_noise, epoch, show=True, fig_size=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_epochs = 10\n",
    "k = 1\n",
    "test_noise = noise(64)\n",
    "\n",
    "generator.train()\n",
    "discriminator.train()\n",
    "for epoch in range(num_epochs):\n",
    "    g_error = 0.0\n",
    "    d_error = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        imgs, _ = data\n",
    "        n = len(imgs)\n",
    "        for j in range(k):\n",
    "            fake_data = generator(noise(n)).detach()\n",
    "            real_data = imgs.to(device)\n",
    "            d_error += train_discriminator(d_optim, real_data, fake_data)\n",
    "        fake_data = generator(noise(n))\n",
    "        g_error += train_generator(g_optim, fake_data)\n",
    "\n",
    "    img = generator(test_noise).cpu().detach()\n",
    "    img = make_grid(img)\n",
    "    images.append(img)\n",
    "    g_losses.append(g_error/i)\n",
    "    d_losses.append(d_error/i)\n",
    "    plot_result(generator, fixed_noise, epoch+1, show=True, fig_size=(5, 5))\n",
    "    print('Epoch {}: g_loss: {:.8f} d_loss: {:.8f}\\r'.format(epoch, g_error/i, d_error/i))\n",
    "    \n",
    "print('Training Finished')\n",
    "torch.save(generator.state_dict(), 'mnist_generator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
